# Findings draft

## RQ1: How do early-career individuals in Germany describe trust in human versus AI career coaching?

Participants describe trust in human coaching as relational and situational, built through presence, empathy, and structured questioning. When mentors are distracted or offer generic advice, trust drops and disclosure becomes superficial. Ethical alignment (e.g., refusing to invent metrics) is a key trust trigger.

> Anna: This is an interview about your experiences with career support, including human coaching and AI tools for career questions. It’s voluntary, you can skip any question, and you can stop anytime. With your permission, Im recording it to record audio for transcription.
> (Master Interviews Transcripts.txt:L7-L7)

> Anna: Yeah, my mother does the same hahaha. I understand. What about more formal support like career services, mentors, coaches?
> (Master Interviews Transcripts.txt:L41-L41)

> Daniel: Basic stuff. It felt generic and more for traditional roles. And then I used ADPList, which is more design-specific.
> (Master Interviews Transcripts.txt:L42-L42)

> Daniel: Basic stuff. It felt generic and more for traditional roles. And then I used ADPList, which is more design-specific.
> (Master Interviews Transcripts.txt:L42-L42)

> Daniel: A lot were surface-level. Like they glance at the portfolio and say looks good, and then they talk about their own career a lot. And I’m sitting there thinking, okay, but what do I do tomorrow?
> (Master Interviews Transcripts.txt:L53-L53)

> Daniel: It was like a template advice.
> (Master Interviews Transcripts.txt:L57-L57)

> Daniel: And I was like… how? I can’t invent numbers. And he said, you can approximate.That triggered a trust issue for me.
> (Master Interviews Transcripts.txt:L55-L55)

> Daniel: I don’t want to lie.
> (Master Interviews Transcripts.txt:L55-L55)

> Daniel: It dropped. I trusted his competence in big-tech storytelling, but I didn’t trust his alignment with me, and I didn’t trust the ethics of what he was suggesting. Also he didn’t ask questions about my situation, Germany, language, anything.
> (Master Interviews Transcripts.txt:L57-L57)

Trust in AI is conditional: it is perceived as reliable for drafting and iteration, but limited by authenticity, accuracy, and privacy concerns. Participants often withhold sensitive details and treat AI outputs as drafts requiring human or personal validation.

> Anna: This is an interview about your experiences with career support, including human coaching and AI tools for career questions. It’s voluntary, you can skip any question, and you can stop anytime. With your permission, Im recording it to record audio for transcription.
> (Master Interviews Transcripts.txt:L7-L7)

> Anna: Yes, exactly. We’ll anonymize everything and use a pseudonym like “Daniel,” and remove identifying details. Are there any topics you’d prefer not to discuss?
> (Master Interviews Transcripts.txt:L9-L9)

> Daniel: LinkedIn mainly. Also company career pages. Sometimes Wellfound.
> (Master Interviews Transcripts.txt:L33-L33)

> Daniel: Yeah, that’s okay. As long as it’s anonymous, right?
> (Master Interviews Transcripts.txt:L8-L8)

> Anna: Yes, exactly. We’ll anonymize everything and use a pseudonym like “Daniel,” and remove identifying details. Are there any topics you’d prefer not to discuss?
> (Master Interviews Transcripts.txt:L9-L9)

> Anna: Do you have privacy concerns when using it?
> (Master Interviews Transcripts.txt:L77-L77)

## RQ2: How is perceived effectiveness defined and evaluated for human versus AI coaching?

Perceived effectiveness is defined by actionable clarity—specific changes to make, concrete plans, and improved outputs. Human coaching is seen as effective when it translates context into tailored action steps; otherwise it is experienced as warm but ineffective. AI is rated as effective for production tasks (CV/LinkedIn revisions, phrasing) but weak for direction-setting and deeper decision-making.

> Daniel: And then a meditation app where it was more UI polish. Sometimes I do end-to-end research planning, interviews, journey maps, wireframes, prototyping in Figma, handoff. But in small projects it’s often like we need UI by next Friday, so you don’t do proper research, you just guess.
> (Master Interviews Transcripts.txt:L29-L29)

> Daniel: Something actionable. Like, change this section of your case study, or your headline is unclear, or here are keywords you’re missing.If it’s concrete, I can do it. If it’s motivational talk, it feels nice for a moment, but then I still don’t know what to do.
> (Master Interviews Transcripts.txt:L46-L46)

> Daniel: She was fully present. She took notes and told me she’s taking notes. She shared her screen and made a little structure, goal constraints strengths, gaps, actions.
> (Master Interviews Transcripts.txt:L63-L63)

> Anna: When you need career support like practical or emotional then who or what do you usually turn to?
> (Master Interviews Transcripts.txt:L39-L39)

> Anna: Do you ever use it for emotional support during the job search?
> (Master Interviews Transcripts.txt:L81-L81)

> Daniel: Sometimes. When I get rejected I ask how to cope. It’s comforting in a shallow way because it doesn’t judge me.
> (Master Interviews Transcripts.txt:L82-L83)

> Anna: This is an interview about your experiences with career support, including human coaching and AI tools for career questions. It’s voluntary, you can skip any question, and you can stop anytime. With your permission, Im recording it to record audio for transcription.
> (Master Interviews Transcripts.txt:L7-L7)

> Anna: Yes, exactly. We’ll anonymize everything and use a pseudonym like “Daniel,” and remove identifying details. Are there any topics you’d prefer not to discuss?
> (Master Interviews Transcripts.txt:L9-L9)

> Daniel: LinkedIn mainly. Also company career pages. Sometimes Wellfound.
> (Master Interviews Transcripts.txt:L33-L33)

## RQ3: How does trust interact with perceived effectiveness, and what hybrid configurations are preferred?

Trust is described as a multiplier for effectiveness: when trust is high, participants act faster and with less second-guessing; when trust is low, implementation slows and advice is filtered. Hybrid configurations are preferred when AI supports preparation and drafting while humans provide contextual nuance, accountability, and reality checks for the German market.

> Daniel: Exactly. Trust makes implementation faster. Distrust makes me overthink.
> (Master Interviews Transcripts.txt:L118-L118)

> Daniel: Trust is like a multiplier.
> (Master Interviews Transcripts.txt:L118-L118)

> Daniel: And that bothers me.
> (Master Interviews Transcripts.txt:L29-L29)

> Anna: What bothers you about it?
> (Master Interviews Transcripts.txt:L30-L30)

> Daniel: After many rejections, I start thinking I’m the problem. But I also know the market is tough. So it’s both.
> (Master Interviews Transcripts.txt:L37-L38)

> Daniel: Okay. 2) Participant context & career situation
> (Master Interviews Transcripts.txt:L12-L13)

> Daniel: Okay, um… I’m 24, I’m a UX/UI designer. I’m in Germany now, in Berlin. I moved here almost three years ago.
> (Master Interviews Transcripts.txt:L15-L15)

> Daniel: Honestly… whether I should stay in UX or pivot to something differentt. Like product, or maybe UI-only, or even something outside design. Because the junior UX market feels saturated, and also the German language requirement blocks me a lot.
> (Master Interviews Transcripts.txt:L19-L19)

