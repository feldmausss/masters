# Step 7: Participant Ratings (0-10 Scale)

## Overview

This document compiles the 0-10 ratings provided by participants across interviews for trust and perceived effectiveness of human coaching versus AI tools. Not all participants provided numerical ratings; some interviews used more qualitative assessment approaches.

---

## Ratings Table

| Participant | Human Trust (0-10) | AI Trust (0-10) | Human Effectiveness (0-10) | AI Effectiveness (0-10) | Notes |
|-------------|-------------------|-----------------|---------------------------|------------------------|-------|
| Daniel | 6.5 | 6 | 7 | 7 | Conditional on context match |
| Simon | 7 | 6 | 7 | 7 | AI trust lower for facts/visa info |
| Lisa | 7 | 5 | 7 | 6 | Human preferred for depth |
| Laura #1 | 6 | 6 | 7 | 6 | Trust depends on coach quality |
| Oleg | 7 | 7 | 7 | 7 | High AI engagement for technical |
| Lena | 6 | 5 | 7 | 5 | Prefers human accountability |
| Mehmet | 6 | 6 | 6 | 6 | Hybrid preference |
| Sofia | 7 | 6 | 8 | 6 | Strong human coaching experience |
| Jonas | 7 | 8 | 7 | 8 | High AI sophistication (works in AI) |
| Alina | 6 | 5 | 6 | 5 | Academia context, less AI use |
| Pierre | 6 | 5 | 6 | 5 | Traditional industry (logistics) |
| Noura | 7 | 6 | 7 | 7 | Balanced perspective |
| Slava | 6 | 7 | 6 | 7 | Developer, high AI comfort |
| Silvia | 7 | 6 | 8 | 6 | Positive human coaching experience |
| Mihir | 7.5 | 6 | 7 | 6.5 | AI trust higher for technical learning |
| Katharina | 7 | 4 | 8 | 5 | Strong coach, limited AI for sensitive |
| Amir | 6 | 8 | 5 | 8 | Sophisticated AI reflection routine |
| Laura #2 | 6.5-7 | 7.5 | 5.5 | 9 | AI-driven decision; highest AI effectiveness |
| Tobias | 4 | 7 | 2 | 6 | Bad coach experience; AI as refuge |

---

## Summary Statistics (Descriptive Only)

### Trust Ratings

**Human Coach Trust:**
- Range: 4 - 7.5
- Mean: 6.5
- Most common: 6-7 range

**AI Tool Trust:**
- Range: 4 - 8
- Mean: 6.2
- Most common: 5-7 range

### Effectiveness Ratings

**Human Coaching Effectiveness:**
- Range: 2 - 8
- Mean: 6.5
- Most common: 6-7 range

**AI Tool Effectiveness:**
- Range: 5 - 9
- Mean: 6.4
- Most common: 5-7 range

---

## Descriptive Observations

### Observation 1: Trust and Effectiveness Are Correlated but Not Identical

Participants who reported high trust generally reported high effectiveness, but exceptions exist:
- **Amir**: High AI trust (8) and effectiveness (8) with lower human effectiveness (5) despite moderate human trust (6) — reflects access and fit issues rather than inherent human coaching problems
- **Tobias**: Very low human effectiveness (2) with low trust (4) after negative coaching experience — demonstrates trust-effectiveness link
- **Laura #2**: Very high AI effectiveness (9) exceeding AI trust (7.5) — suggests effectiveness can outpace trust for bounded tasks

### Observation 2: Background Influences AI Comfort

Participants with technical backgrounds or working in tech-adjacent fields tended to rate AI trust and effectiveness higher:
- **Jonas** (AI Product Specialist): AI Trust 8, AI Effectiveness 8
- **Slava** (Frontend Developer): AI Trust 7, AI Effectiveness 7
- **Amir** (HCI student, UX researcher): AI Trust 8, AI Effectiveness 8

Participants in more traditional industries or academic settings tended toward lower AI ratings:
- **Pierre** (Logistics): AI Trust 5, AI Effectiveness 5
- **Alina** (Academia): AI Trust 5, AI Effectiveness 5

### Observation 3: Negative Experiences Have Lasting Impact

**Tobias's ratings** (Human Trust: 4, Human Effectiveness: 2) are the lowest in the dataset, reflecting a single bad coaching experience. His subsequent AI ratings (7, 6) show he found an alternative support mechanism. This suggests that:
- One bad experience can create lasting coaching aversion
- AI can serve as a refuge when human trust has been damaged
- The quality variance in human coaching matters enormously

### Observation 4: AI Effectiveness Can Equal or Exceed Human Effectiveness for Specific Users

Three participants rated AI effectiveness equal to or higher than human effectiveness:
- **Laura #2**: AI 9 vs Human 5.5
- **Amir**: AI 8 vs Human 5
- **Jonas**: AI 8 vs Human 7

Common factors among these participants:
- Sophisticated, intentional AI use patterns (custom prompts, structured routines)
- Specific use cases where AI excels (decision structuring, reflection, iteration)
- Access/cost barriers to quality human coaching

### Observation 5: High Human Effectiveness Tied to Positive Coaching Experiences

The highest human effectiveness ratings came from participants with specifically positive coaching experiences:
- **Katharina**: Human Effectiveness 8 (5-session structured coaching with accountability)
- **Sofia**: Human Effectiveness 8 (supportive coaching during career transition)
- **Silvia**: Human Effectiveness 8 (values-clarifying coaching experience)

These participants also rated AI effectiveness lower (5-6), suggesting their high human ratings reflect comparison to a high bar.

### Observation 6: Trust Gap Between Modalities is Narrow

The average difference between human and AI trust ratings is only **0.3 points** (6.5 vs 6.2). This suggests:
- AI is not dramatically less trusted than humans for career support
- Trust may be task-specific rather than modality-specific
- The "AI can't be trusted" narrative may not reflect user experience

However, the trust *type* differs qualitatively (relational vs. functional) even when quantitative ratings are similar.

---

## Participant Profiles by Rating Pattern

### High Human, Lower AI (Traditional Pattern)
- Katharina, Sofia, Silvia, Lena
- Characterized by: Positive human coaching experiences, less sophisticated AI use
- Quote pattern: "AI can help with drafts but humans understand me"

### High AI, Lower Human (Inverted Pattern)
- Amir, Laura #2, Tobias
- Characterized by: Access barriers to human coaching, sophisticated AI routines, or negative human experiences
- Quote pattern: "AI is always available and doesn't judge"

### Balanced (Similar Ratings)
- Daniel, Simon, Oleg, Mehmet, Noura
- Characterized by: Task-specific preferences, clear mental model of complementary use
- Quote pattern: "AI for X, human for Y"

### High Both (Positive All Around)
- Jonas, Slava
- Characterized by: Tech backgrounds, high comfort with both modalities
- Quote pattern: "I use both extensively for different things"

---

## Implications for Research Questions

### RQ1 Implication
Trust ratings for humans and AI are more similar than different in magnitude, but the *nature* of trust differs. Human trust is about relational safety; AI trust is about functional reliability.

### RQ2 Implication
Effectiveness ratings are highly context-dependent. Participants with positive coaching experiences rate humans higher; participants with sophisticated AI routines rate AI higher. This suggests effectiveness is influenced by quality and intentionality of use, not just modality.

### RQ3 Implication
The trust-effectiveness correlation is visible in the data:
- Tobias: Low human trust (4) → Low human effectiveness (2)
- Katharina: High human trust (7) → High human effectiveness (8)
- Laura #2: High AI trust (7.5) → Very high AI effectiveness (9)

However, exceptions exist (Amir's human trust-effectiveness gap), confirming that trust is necessary but not sufficient for effectiveness.

---

## Conclusion

The ratings data supports the qualitative findings:
1. Trust and effectiveness are related but can diverge
2. AI and human support have similar trust levels but different trust types
3. Effectiveness is highly dependent on quality of use and context
4. Negative experiences have disproportionate lasting impact
5. Sophisticated users can achieve high effectiveness with AI for appropriate tasks

The universal hybrid preference (qualitative finding) is not contradicted by ratings—participants want both modalities, with task-appropriate deployment.
