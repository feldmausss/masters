# Step 7: Extract Ratings Table

---

## PARTICIPANT RATINGS SUMMARY (0-10 Scale)

All ratings were collected via micro-poll during interviews. Participants were asked to rate on a 0-10 scale where 0 = no trust/not effective at all, and 10 = complete trust/extremely effective.

---

## COMPLETE RATINGS TABLE

| # | Participant | Human Trust | AI Trust | Human Eff | AI Eff | Notes |
|---|-------------|-------------|----------|-----------|--------|-------|
| 1 | Daniel | 6 | 5 | 4 | 6 | Trusts concept but not automatically the person; AI useful for writing but misses context |
| 2 | Simon | 7 | 6 | 7 | 8 | Open but not naive; AI effective for structure but needs verification |
| 3 | Lisa | 8 | 5 | 9 | 6 | Strong coaching experience; trusts humans for empathy, AI for drafts only |
| 4 | Laura #1 | 2 | 7 | 3 | 8 | Deep distrust of coaching industry; high AI effectiveness for planning |
| 5 | Oleg | 7 | 4 | 8 | 5 | Trusts right humans; AI lacks context for high-stakes decisions |
| 6 | Lena | 6 | 5 | 6 | 6 | Open but cautious on both; AI for small tasks mainly |
| 7 | Mehmet | 6 | 7.5 | 5 | 8 | Daily AI user; trusts AI for language more than humans for coaching |
| 8 | Sofia | 7 | 5.5 | 6 | 7 | Humans warmer but inconsistent; AI faster but suspicious of confidence |
| 9 | Jonas | 7 | 4 | 6 | 3 | Privacy concerns with AI; AI not effective for career (8 for technical) |
| 10 | Alina | 7 | 5 | 4 | 7 | Human coaching emotionally helpful but not actionable for pivot |
| 11 | Pierre | 8 | 4 | 7 | 5 | Strong mentor experience; AI lacks nuance for design/hardware |
| 12 | Noura | 6 | 7 | 5 | 8 | One good mentor raised human trust; AI for weekly practical help |
| 13 | Slava | 7 | 6 | 7 | 7 | Believes good mentor could be 9; AI effective for ops tasks |
| 14 | Silvia | 7 | 4 | 6 | 7 | Group coaching helped via peers; AI not trusted for identity |
| 15 | Mihir | 7.5 | 6 | 7 | 6.5 | Good mentor experience; AI helps daily but not for big picture |
| 16 | Katharina | 7 | 4 | 8 | 5 | Strong coaching experience created behavior change; AI for narrow tasks |
| 17 | Amir | 6 | 8 | 5 | 8 | Intensive AI user; uses AI as structured reflection partner |
| 18 | Laura #2 | 7 | 7.5 | 5.5 | 9 | AI-driven major career decision; AI enabled final clarity |
| 19 | Tobias | 4 | 7 | 2 | 6 | Trust rupture with coach; AI cannot shame (emotional safety) |

---

## AGGREGATE STATISTICS

### Trust Ratings

| Measure | Human Trust | AI Trust |
|---------|-------------|----------|
| **Mean** | 6.3 | 5.7 |
| **Median** | 7 | 6 |
| **Range** | 2-8 | 4-8 |
| **Std Dev** | 1.4 | 1.3 |

### Effectiveness Ratings

| Measure | Human Eff | AI Eff |
|---------|-----------|--------|
| **Mean** | 5.6 | 6.5 |
| **Median** | 6 | 6.5 |
| **Range** | 2-9 | 3-9 |
| **Std Dev** | 1.8 | 1.5 |

---

## TRUST-EFFECTIVENESS PATTERNS

### Pattern 1: Human Trust > AI Trust (n=12, 63%)

| Participant | H-Trust | AI-Trust | Difference | Key Reason |
|-------------|---------|----------|------------|------------|
| Lisa | 8 | 5 | +3 | Empathy and experience from coach |
| Pierre | 8 | 4 | +4 | Mentor competence and honesty |
| Oleg | 7 | 4 | +3 | Privacy and accuracy concerns with AI |
| Jonas | 7 | 4 | +3 | Privacy/hallucination concerns |
| Silvia | 7 | 4 | +3 | AI not trusted for identity questions |
| Katharina | 7 | 4 | +3 | AI for narrow tasks only |
| Sofia | 7 | 5.5 | +1.5 | AI too confident, suspicious |
| Alina | 7 | 5 | +2 | AI not deep enough |
| Slava | 7 | 6 | +1 | AI as assistant, not expert |
| Mihir | 7.5 | 6 | +1.5 | AI context/accuracy uncertain |
| Daniel | 6 | 5 | +1 | AI misses context |
| Lena | 6 | 5 | +1 | AI for small tasks only |

### Pattern 2: AI Trust > Human Trust (n=6, 32%)

| Participant | H-Trust | AI-Trust | Difference | Key Reason |
|-------------|---------|----------|------------|------------|
| Laura #1 | 2 | 7 | +5 | Deep distrust of coaching industry |
| Mehmet | 6 | 7.5 | +1.5 | Daily AI user, helps with language |
| Noura | 6 | 7 | +1 | AI consistent and non-judgmental |
| Amir | 6 | 8 | +2 | AI as structured reflection partner |
| Tobias | 4 | 7 | +3 | Trust rupture with human; AI cannot shame |
| Laura #2 | 7 | 7.5 | +0.5 | AI enabled major decision |

### Pattern 3: Equal Trust (n=1, 5%)

| Participant | H-Trust | AI-Trust | Key Reason |
|-------------|---------|----------|------------|
| Simon | 7 | 6 | Approximately equal, different use cases |

---

## EFFECTIVENESS PATTERNS

### Pattern 1: AI Eff > Human Eff (n=12, 63%)

| Participant | H-Eff | AI-Eff | Difference | Key Reason |
|-------------|-------|--------|------------|------------|
| Laura #1 | 3 | 8 | +5 | Would resist human coaching; AI planning very effective |
| Laura #2 | 5.5 | 9 | +3.5 | AI drove major career decision |
| Tobias | 2 | 6 | +4 | Human coaching failed due to rupture |
| Mehmet | 5 | 8 | +3 | AI helps daily with language |
| Noura | 5 | 8 | +3 | AI reduces stress, gives concrete outputs |
| Amir | 5 | 8 | +3 | AI for structured reflection |
| Alina | 4 | 7 | +3 | AI helps with German and structure |
| Daniel | 4 | 6 | +2 | Only one human session really changed things |
| Sofia | 6 | 7 | +1 | AI helps when stuck; faster |
| Silvia | 6 | 7 | +1 | AI effective for tasks, not identity |
| Simon | 7 | 8 | +1 | AI overcomes blank-page paralysis |
| Slava | 7 | 7 | 0 | Equal—AI for ops, human for direction |

### Pattern 2: Human Eff > AI Eff (n=5, 26%)

| Participant | H-Eff | AI-Eff | Difference | Key Reason |
|-------------|-------|--------|------------|------------|
| Lisa | 9 | 6 | +3 | Coach creates real forward movement |
| Oleg | 8 | 5 | +3 | Human for leadership and emotional topics |
| Katharina | 8 | 5 | +3 | Coaching created behavior change |
| Pierre | 7 | 5 | +2 | Mentor gave clarity and actions |
| Jonas | 6 | 3 | +3 | AI not effective for career (only technical) |

### Pattern 3: Approximately Equal (n=2, 11%)

| Participant | H-Eff | AI-Eff | Key Reason |
|-------------|-------|--------|------------|
| Lena | 6 | 6 | Both moderately helpful |
| Mihir | 7 | 6.5 | Mentor helped; AI helps with small tasks |

---

## TRUST-EFFECTIVENESS CORRELATIONS

### Within-Modality Correlations

| Relationship | Direction | Interpretation |
|--------------|-----------|----------------|
| Human Trust vs Human Eff | Moderate positive (r ≈ 0.45) | Higher trust generally associated with higher perceived effectiveness |
| AI Trust vs AI Eff | Moderate positive (r ≈ 0.52) | Trust and effectiveness co-vary, but exceptions exist |

### Cross-Modality Patterns

| Pattern | n | % | Example |
|---------|---|---|---------|
| H-Trust > AI-Trust AND H-Eff > AI-Eff | 5 | 26% | Lisa, Oleg, Pierre, Katharina, Jonas |
| AI-Trust > H-Trust AND AI-Eff > H-Eff | 5 | 26% | Laura #1, Mehmet, Noura, Amir, Tobias |
| H-Trust > AI-Trust BUT AI-Eff > H-Eff | 6 | 32% | Daniel, Sofia, Alina, Silvia, Simon, Slava |
| AI-Trust > H-Trust BUT H-Eff > AI-Eff | 1 | 5% | Laura #2 (marginal) |
| Approximately equal | 2 | 11% | Lena, Mihir |

---

## KEY INSIGHTS FROM RATINGS

### 1. Trust Does Not Automatically Equal Effectiveness

**The Divergence Pattern (32% of participants)**
Six participants rated human trust higher than AI trust, but AI effectiveness higher than human effectiveness. This supports Theme 5 (Trust-Effectiveness Divergence):

- **Daniel**: Trusts humans more (6 vs 5) but AI more effective (6 vs 4)
- **Sofia**: Trusts humans more (7 vs 5.5) but AI more effective (7 vs 6)
- **Alina**: Trusts humans more (7 vs 5) but AI more effective (7 vs 4)
- **Silvia**: Trusts humans more (7 vs 4) but AI more effective (7 vs 6)
- **Simon**: Similar trust but AI more effective (8 vs 7)
- **Slava**: Similar trust and effectiveness (7/7 for both)

**Interpretation**: Trust is a separate construct from effectiveness. Participants can trust humans emotionally while finding AI more practically effective for certain tasks.

### 2. AI Effectiveness Often Exceeds AI Trust

For 11 of 19 participants (58%), AI effectiveness rating exceeded AI trust rating:

| Participant | AI Trust | AI Eff | Gap |
|-------------|----------|--------|-----|
| Silvia | 4 | 7 | +3 |
| Sofia | 5.5 | 7 | +1.5 |
| Mehmet | 7.5 | 8 | +0.5 |
| Laura #2 | 7.5 | 9 | +1.5 |
| Alina | 5 | 7 | +2 |
| Daniel | 5 | 6 | +1 |
| Laura #1 | 7 | 8 | +1 |
| Simon | 6 | 8 | +2 |
| Noura | 7 | 8 | +1 |
| Amir | 8 | 8 | 0 |
| Slava | 6 | 7 | +1 |

**Silvia's explanation**: "I can still use AI pragmatically, like a tool, without trusting it emotionally. But for a coach, you cannot."

**Interpretation**: AI can be effective for bounded tasks even with partial trust because verification substitutes for trust. This aligns with Theme 5.

### 3. Human Effectiveness More Variable

Human effectiveness ratings showed higher variance (std dev 1.8 vs 1.5 for AI), ranging from 2 (Tobias) to 9 (Lisa).

**Highest Human Effectiveness (8-9)**:
- Lisa (9): Strong paid coaching experience with concrete outcomes
- Katharina (8): Coaching created behavior change and accountability
- Oleg (8): Good mentoring for leadership decisions

**Lowest Human Effectiveness (2-4)**:
- Tobias (2): Trust rupture prevented engagement with useful content
- Laura #1 (3): Would resist coaching; self-directed preference
- Daniel (4): Only one session was transformative

**Interpretation**: Human effectiveness is highly context-dependent—the right match produces exceptional results, but mismatches or ruptures produce near-zero effectiveness.

### 4. Extreme Cases Illuminate Mechanisms

**Laura #1 (H-Trust: 2, AI-Trust: 7, H-Eff: 3, AI-Eff: 8)**
Extreme distrust of coaching industry but high AI effectiveness. Shows that AI can serve participants who would never engage with human coaching.

**Tobias (H-Trust: 4, AI-Trust: 7, H-Eff: 2, AI-Eff: 6)**
Trust rupture with human coach (felt dismissed and labeled) destroyed effectiveness. AI provides safety from judgment. Demonstrates how quickly trust rupture destroys human effectiveness.

**Laura #2 (H-Trust: 7, AI-Trust: 7.5, H-Eff: 5.5, AI-Eff: 9)**
AI drove a major career decision through structured 3-week process. Shows AI can be primary decision support for some individuals and decisions.

**Lisa (H-Trust: 8, AI-Trust: 5, H-Eff: 9, AI-Eff: 6)**
Strong paid coaching relationship with accountability. Shows what optimal human coaching produces—highest effectiveness rating in sample.

### 5. Task Type Moderates Trust-Effectiveness Link

**Jonas's split ratings reveal the moderation effect**:
- AI Trust for career: 4
- AI Effectiveness for career: 3
- AI Effectiveness for technical: 8

Jonas trusts AI for technical tasks (coding) but not for career decisions. Effectiveness follows trust when task type changes. This supports Theme 3 (Complementary Competencies).

---

## DESCRIPTIVE SUMMARY

### Trust Findings

**Human trust** averaged 6.3/10 with a median of 7, indicating moderate-to-high general trust in human coaching *potential*, though with significant individual variation. The lowest ratings (Laura #1: 2, Tobias: 4) came from participants with either ideological resistance or negative experiences. The highest (Lisa: 8, Pierre: 8) came from those with positive coaching/mentoring experiences.

**AI trust** averaged 5.7/10 with a median of 6, indicating moderate trust. Trust drivers included consistency, non-judgment, and availability. Trust barriers included privacy concerns, hallucinations, overconfidence, and lack of contextual understanding. Notably, AI trust exceeded human trust for 6 participants (32%), often those who had negative human experiences (Tobias) or intensive AI use patterns (Amir, Mehmet).

### Effectiveness Findings

**Human effectiveness** averaged 5.6/10 with high variability (range 2-9, std dev 1.8). This variability reflects the high-stakes nature of human coaching: when it works (right match, trust intact), it produces exceptional results (Lisa: 9, Katharina: 8). When it fails (trust rupture, mismatch), it produces near-zero value (Tobias: 2).

**AI effectiveness** averaged 6.5/10 with lower variability (range 3-9, std dev 1.5). AI effectiveness was more consistent across participants, reflecting its strength in bounded cognitive tasks that don't require deep trust. The highest AI effectiveness (Laura #2: 9) came from structured, intensive use for decision-making. The lowest (Jonas: 3) came from a privacy-conscious participant who limited AI career use.

### Trust-Effectiveness Relationship

The ratings reveal that **trust and effectiveness are related but distinct constructs**:

1. **Trust is not sufficient**: High trust without structure produces emotional support but not action (trusted but not effective pattern)

2. **Trust is not always necessary**: For bounded tasks, effectiveness can occur with partial trust through verification (effective but not trusted pattern)

3. **Trust is essential for depth**: For emotional and high-stakes work, low trust prevents the disclosure that enables effectiveness (gateway mechanism)

4. **Task type moderates**: The trust-effectiveness link is strong for relational/identity tasks and weak for structured/cognitive tasks

### Preference Implications

The ratings support **universal hybrid preference** (Theme 6):
- Human trust is higher on average, suggesting humans are trusted for relational safety
- AI effectiveness is higher on average, suggesting AI excels at producing practical outputs
- The combination leverages human trust for depth and AI effectiveness for structure

---

## VISUAL: RATINGS DISTRIBUTION

```
TRUST RATINGS DISTRIBUTION
                  Human Trust              AI Trust
              Low (0-4)  Mid (5-7)  High (8-10)    Low (0-4)  Mid (5-7)  High (8-10)
Participants:     2         14          3              5         12          2

EFFECTIVENESS RATINGS DISTRIBUTION
                  Human Eff              AI Eff
              Low (0-4)  Mid (5-7)  High (8-10)    Low (0-4)  Mid (5-7)  High (8-10)
Participants:     4         12          3              2         11          6
```

---

## TRUST-EFFECTIVENESS QUADRANT

```
                         HIGH EFFECTIVENESS
                              │
         ┌────────────────────┼────────────────────┐
         │                    │                    │
         │   HIGH TRUST       │   HIGH TRUST       │
         │   LOW EFF          │   HIGH EFF         │
         │                    │                    │
         │   "Trusted but     │   "Optimal"        │
         │    Ineffective"    │                    │
         │                    │                    │
         │   (Friends,        │   (Lisa H, Pierre  │
         │    kind mentors)   │    H, Katharina H) │
         │                    │                    │
LOW ─────┼────────────────────┼────────────────────┼───── HIGH
TRUST    │                    │                    │     TRUST
         │   LOW TRUST        │   LOW TRUST        │
         │   LOW EFF          │   HIGH EFF         │
         │                    │                    │
         │   "Dysfunctional"  │   "Effective but   │
         │                    │    Not Trusted"    │
         │                    │                    │
         │   (Tobias H,       │   (Silvia AI,      │
         │    Laura #1 H)     │    Alina AI,       │
         │                    │    Laura #1 AI)    │
         │                    │                    │
         └────────────────────┼────────────────────┘
                              │
                         LOW EFFECTIVENESS

H = Human ratings for that participant
AI = AI ratings for that participant
```

---

## CONCLUSION

The ratings data quantitatively support the thematic findings:

1. **Theme 1 (Human Trust Architecture)** is reflected in the moderate-high human trust ratings (mean 6.3) with high variance, showing trust depends on specific behaviors and can be damaged (Tobias: 4).

2. **Theme 2 (AI's Bounded Safety)** is reflected in consistent but moderate AI trust (mean 5.7), with higher trust from those seeking judgment-free space (Amir: 8, Tobias: 7).

3. **Theme 3 (Complementary Competencies)** is shown by Jonas's split ratings (AI career eff: 3, AI technical eff: 8) and the pattern where trust/effectiveness profiles differ by task type.

4. **Theme 4 (Trust as Gateway)** is supported by the positive correlation between trust and effectiveness, particularly for human coaching.

5. **Theme 5 (Trust-Effectiveness Divergence)** is quantified by the 32% who rated human trust higher but AI effectiveness higher, and the 58% whose AI effectiveness exceeded AI trust.

6. **Theme 6 (Hybrid Ideal)** is supported by human trust averaging higher while AI effectiveness averages higher—suggesting each modality serves a distinct function that hybrid models can combine.
